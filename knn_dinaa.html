
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Deteksi Outlier dengan K-Nearest Neighbors (KNN) dalam Data Understanding &#8212; Penambangan Data</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'knn_dinaa';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Deteksi Outlier dengan metode Local Outlier Factor (LOF) dalam Data Understanding" href="LOF.html" />
    <link rel="prev" title="Tugas 2" href="tugas2.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/IMG_0531.JPG" class="logo__image only-light" alt="Penambangan Data - Home"/>
    <img src="_static/IMG_0531.JPG" class="logo__image only-dark pst-js-only" alt="Penambangan Data - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    PENAMBANGAN DATA
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Tugas_1.html">Tugas 1</a></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="tugas2.html">Tugas 2</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#"><strong>Deteksi Outlier dengan K-Nearest Neighbors (KNN) dalam Data Understanding</strong></a></li>

<li class="toctree-l2"><a class="reference internal" href="LOF.html"><strong>Deteksi Outlier dengan metode Local Outlier Factor (LOF) dalam Data Understanding</strong></a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="UTS.html"><strong>UTS PENDAT</strong></a></li>


<li class="toctree-l1"><a class="reference internal" href="K_Means.html"><strong>Algoritma <em>K-Means</em></strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="Fuzzy.html"><strong>FUZZY C-MEANS</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="DecisionTree.html">Decision Tree</a></li>
<li class="toctree-l1"><a class="reference internal" href="BinningTeknik.html">Teknik Binning</a></li>
<li class="toctree-l1"><a class="reference internal" href="Pra_Uas.html">Prediksi Jenis Wine berdasarkan hasil analisis kimia terhadap wine dari tiga varietas Anggur</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fknn_dinaa.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/knn_dinaa.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Deteksi Outlier dengan K-Nearest Neighbors (KNN) dalam Data Understanding</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#"><strong>Deteksi Outlier dengan K-Nearest Neighbors (KNN) dalam Data Understanding</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kesimpulan"><strong>kesimpulan</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pemisah-outlier-dari-data">Pemisah Outlier dari data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#menghitung-akurasi-data">Menghitung akurasi data</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#implementasi-naive-bayes-pada-data-iris"><strong>Implementasi Naive Bayes pada Data IRIS</strong></a></li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="deteksi-outlier-dengan-k-nearest-neighbors-knn-dalam-data-understanding">
<h1><strong>Deteksi Outlier dengan K-Nearest Neighbors (KNN) dalam Data Understanding</strong><a class="headerlink" href="#deteksi-outlier-dengan-k-nearest-neighbors-knn-dalam-data-understanding" title="Link to this heading">#</a></h1>
<p>Deteksi outlier menggunakan metode K-Nearest Neighbors (KNN) merupakan salah satu teknik yang digunakan untuk mengidentifikasi data yang menyimpang dari pola mayoritas. KNN bekerja dengan cara mengukur jarak antara satu data dengan data lainnya dalam dataset. Jika sebuah data memiliki jarak yang jauh dari tetangga terdekatnya, maka data tersebut berpotensi sebagai outlier. Metode ini sangat berguna pada tahap Data Understanding karena dapat membantu menemukan data ekstrem yang mungkin mempengaruhi hasil analisis atau pemodelan.</p>
<p><strong>Langkah-Langkah Deteksi Outlier dengan KNN:</strong></p>
<ul class="simple">
<li><p>Menentukan Nilai k</p></li>
</ul>
<p>Langkah pertama adalah menentukan jumlah tetangga terdekat (k) yang akan digunakan untuk menghitung jarak. Nilai k ini bisa ditentukan berdasarkan eksperimen, dengan angka umum berkisar antara 5 hingga 20.</p>
<ul class="simple">
<li><p>Menghitung Jarak Antar Data</p></li>
</ul>
<p>Selanjutnya, dilakukan perhitungan jarak antara setiap data dengan data lainnya menggunakan rumus jarak seperti Euclidean Distance atau Manhattan Distance, tergantung pada karakteristik data.</p>
<ul class="simple">
<li><p>Mencari k Tetangga Terdekat</p></li>
</ul>
<p>Setelah jarak dihitung, dipilih k data terdekat untuk setiap titik data.</p>
<ul class="simple">
<li><p>Menghitung Skor Outlier
Skor outlier dihitung dengan cara menghitung rata-rata jarak antara sebuah data dengan k tetangganya. Semakin besar rata-rata jarak ini, semakin besar pula kemungkinan data tersebut merupakan outlier.</p></li>
<li><p>Menentukan Outlier Terakhir
ditentukan ambang batas (threshold) untuk memisahkan mana data yang dianggap normal dan mana yang termasuk outlier berdasarkan skor yang diperoleh.</p></li>
</ul>
<section id="kesimpulan">
<h2><strong>kesimpulan</strong><a class="headerlink" href="#kesimpulan" title="Link to this heading">#</a></h2>
<p>Metode KNN untuk deteksi outlier sangat berguna dalam data understanding, terutama ketika data memiliki pola distribusi yang tidak diketahui sebelumnya. Dengan membandingkan jarak ke tetangga terdekat, metode ini dapat mengidentifikasi titik yang menyimpang secara signifikan dari kelompok data lainnya.</p>
<p>kode di bawah ini adalah Perintah %pip install pymysql digunakan untuk menginstal pustaka PyMySQL, yang berfungsi sebagai konektor antara Python dan database MySQL. Dengan pustaka ini, pengguna dapat menjalankan perintah SQL seperti INSERT, SELECT, UPDATE, DELETE, dan mengelola database langsung dari skrip Python.</p>
<p>Sementara itu, perintah %pip install psycopg2 digunakan untuk menginstal pustaka psycopg2, yang merupakan driver utama untuk berkomunikasi dengan database PostgreSQL. Pustaka ini memungkinkan pengguna untuk menghubungkan Python ke PostgreSQL, menjalankan query, dan mengelola data dengan mudah.</p>
<p>Kedua pustaka ini sangat berguna dalam pengembangan aplikasi berbasis database, baik untuk kebutuhan analisis data, pengelolaan transaksi, maupun pengembangan web yang menggunakan MySQL atau PostgreSQL sebagai sistem manajemen basis data (DBMS).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">pip</span> install pymysql
<span class="o">%</span><span class="k">pip</span> install psycopg2
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: pymysql in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.1.1)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold">[</span><span class=" -Color -Color-Blue">notice</span><span class=" -Color -Color-Bold">]</span> A new release of pip is available: <span class=" -Color -Color-Red">24.3.1</span> -&gt; <span class=" -Color -Color-Green">25.0.1</span>
<span class=" -Color -Color-Bold">[</span><span class=" -Color -Color-Blue">notice</span><span class=" -Color -Color-Bold">]</span> To update, run: <span class=" -Color -Color-Green">python3 -m pip install --upgrade pip</span>
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Note: you may need to restart the kernel to use updated packages.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: psycopg2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (2.9.10)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold">[</span><span class=" -Color -Color-Blue">notice</span><span class=" -Color -Color-Bold">]</span> A new release of pip is available: <span class=" -Color -Color-Red">24.3.1</span> -&gt; <span class=" -Color -Color-Green">25.0.1</span>
<span class=" -Color -Color-Bold">[</span><span class=" -Color -Color-Blue">notice</span><span class=" -Color -Color-Bold">]</span> To update, run: <span class=" -Color -Color-Green">python3 -m pip install --upgrade pip</span>
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Note: you may need to restart the kernel to use updated packages.
</pre></div>
</div>
</div>
</div>
<p>Kode di bawah ini melakukan deteksi outlier pada dataset Iris yang tersimpan dalam database PostgreSQL dan MySQL menggunakan metode K-Nearest Neighbors (KNN). Data dari kedua database diambil dan digabungkan berdasarkan kolom “id” dan “class”. Setelah itu, fitur numerik (“petal_length”, “petal_width”, “sepal_length”, dan “sepal_width”) digunakan untuk menghitung jarak ke 5 tetangga terdekat (k=5).</p>
<p>Hasil perhitungan jarak rata-rata digunakan untuk menentukan apakah suatu data termasuk outlier, dengan membandingkan nilainya terhadap threshold yang dihitung dari rata-rata jarak ditambah 2 standar deviasi. Data yang memiliki nilai lebih besar dari threshold akan dikategorikan sebagai outlier.</p>
<p>Setelah proses deteksi selesai, hasilnya ditampilkan dalam bentuk tabel yang menunjukkan id, class, fitur numerik, nilai KNN distance, dan status outlier. Selain itu, jumlah total outlier dihitung dan ditampilkan secara terpisah.</p>
<p>Agar lebih mudah dipahami, hasil deteksi outlier juga divisualisasikan dalam bentuk scatter plot menggunakan Seaborn. Plot pertama menunjukkan hubungan antara “sepal_length” dan “sepal_width”, sedangkan plot kedua memperlihatkan hubungan antara “petal_length” dan “petal_width”, dengan outlier diberi warna merah untuk membedakannya dari data normal.</p>
<p>Dengan metode ini, outlier dapat terdeteksi berdasarkan pola kedekatan antar data, sehingga memudahkan dalam memahami penyebaran data dan mengidentifikasi anomali dalam dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">psycopg2</span>
<span class="kn">import</span> <span class="nn">pymysql</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">NearestNeighbors</span>

<span class="k">def</span> <span class="nf">get_pg_data</span><span class="p">():</span>
    <span class="n">conn</span> <span class="o">=</span> <span class="n">psycopg2</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span>
        <span class="n">host</span><span class="o">=</span><span class="s2">&quot;pg-1d952496-dinaaa-269a.i.aivencloud.com&quot;</span><span class="p">,</span>
        <span class="n">user</span><span class="o">=</span><span class="s2">&quot;avnadmin&quot;</span><span class="p">,</span>
        <span class="n">password</span><span class="o">=</span><span class="s2">&quot;AVNS_n1Ru1Ddse4sg_Gpi7Nb&quot;</span><span class="p">,</span>
        <span class="n">database</span><span class="o">=</span><span class="s2">&quot;defaultdb&quot;</span><span class="p">,</span>
        <span class="n">port</span><span class="o">=</span><span class="mi">27730</span>
    <span class="p">)</span>
    <span class="n">cursor</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">cursor</span><span class="p">()</span>
    <span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;SELECT * FROM tabel_b&quot;</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">cursor</span><span class="o">.</span><span class="n">fetchall</span><span class="p">()</span>
    <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">desc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">desc</span> <span class="ow">in</span> <span class="n">cursor</span><span class="o">.</span><span class="n">description</span><span class="p">]</span>
    <span class="n">cursor</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="n">conn</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_mysql_data</span><span class="p">():</span>
    <span class="n">conn</span> <span class="o">=</span> <span class="n">pymysql</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span>
        <span class="n">host</span><span class="o">=</span><span class="s2">&quot;mysql-e89c328-dinaaa-269a.i.aivencloud.com&quot;</span><span class="p">,</span>
        <span class="n">user</span><span class="o">=</span><span class="s2">&quot;avnadmin&quot;</span><span class="p">,</span>
        <span class="n">password</span><span class="o">=</span><span class="s2">&quot;AVNS_GBbKfVRE1qvWkI6gU2s&quot;</span><span class="p">,</span>
        <span class="n">database</span><span class="o">=</span><span class="s2">&quot;iris_mysql&quot;</span><span class="p">,</span>
        <span class="n">port</span><span class="o">=</span><span class="mi">27730</span>
    <span class="p">)</span>
    <span class="n">cursor</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">cursor</span><span class="p">()</span>
    <span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;SELECT * FROM tabel_a&quot;</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">cursor</span><span class="o">.</span><span class="n">fetchall</span><span class="p">()</span>
    <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">desc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">desc</span> <span class="ow">in</span> <span class="n">cursor</span><span class="o">.</span><span class="n">description</span><span class="p">]</span>
    <span class="n">cursor</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="n">conn</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">)</span>

    <span class="c1"># Ambil data dari kedua database</span>
<span class="n">df_postgresql</span> <span class="o">=</span> <span class="n">get_pg_data</span><span class="p">()</span>
<span class="n">df_mysql</span> <span class="o">=</span> <span class="n">get_mysql_data</span><span class="p">()</span>

<span class="c1"># Gabungkan berdasarkan kolom &#39;id&#39;</span>
<span class="n">df_merged</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">df_mysql</span><span class="p">,</span> <span class="n">df_postgresql</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;class&quot;</span><span class="p">],</span> <span class="n">how</span><span class="o">=</span><span class="s2">&quot;inner&quot;</span><span class="p">)</span>

<span class="c1"># Ambil data fitur numerik</span>
<span class="n">feature_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;petal_length&quot;</span><span class="p">,</span> <span class="s2">&quot;petal_width&quot;</span><span class="p">,</span> <span class="s2">&quot;sepal_length&quot;</span><span class="p">,</span> <span class="s2">&quot;sepal_width&quot;</span><span class="p">]</span>
<span class="n">data_values</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="n">feature_columns</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># KNN Outlier Detection</span>
<span class="k">def</span> <span class="nf">knn_outlier_detection</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">neigh</span> <span class="o">=</span> <span class="n">NearestNeighbors</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">neigh</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">distances</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">neigh</span><span class="o">.</span><span class="n">kneighbors</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">avg_distances</span> <span class="o">=</span> <span class="n">distances</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Ambil jarak k-terjauh sebagai skor</span>
    <span class="k">return</span> <span class="n">avg_distances</span>

<span class="c1"># Hitung K-NN distance</span>
<span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;knn_distance&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">knn_outlier_detection</span><span class="p">(</span><span class="n">data_values</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>

<span class="c1"># Tentukan threshold sebagai nilai rata-rata + 2 standar deviasi</span>
<span class="n">threshold</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;knn_distance&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;knn_distance&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
<span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;outlier_knn&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;knn_distance&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">threshold</span>

<span class="c1"># Hapus data outlier</span>
<span class="n">df_filtered</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="o">~</span><span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;outlier_knn&quot;</span><span class="p">]]</span>

<span class="c1"># Cetak hasil setelah outlier dihapus</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_filtered</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Jumlah data setelah outlier dihapus: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">df_filtered</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Visualisasi setelah outlier dihapus</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">df_filtered</span><span class="p">[</span><span class="s2">&quot;sepal_length&quot;</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">df_filtered</span><span class="p">[</span><span class="s2">&quot;sepal_width&quot;</span><span class="p">],</span>
    <span class="n">hue</span><span class="o">=</span><span class="n">df_filtered</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">],</span> <span class="n">palette</span><span class="o">=</span><span class="s2">&quot;deep&quot;</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Data Sepal setelah Outlier Dihapus&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">df_filtered</span><span class="p">[</span><span class="s2">&quot;petal_length&quot;</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">df_filtered</span><span class="p">[</span><span class="s2">&quot;petal_width&quot;</span><span class="p">],</span>
    <span class="n">hue</span><span class="o">=</span><span class="n">df_filtered</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">],</span> <span class="n">palette</span><span class="o">=</span><span class="s2">&quot;deep&quot;</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Data Petal setelah Outlier Dihapus&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> id           class  petal_length  petal_width  sepal_length  sepal_width  knn_distance  outlier_knn
  1     Iris-setosa           1.4          0.2           5.1          3.5      4.007493        False
  2     Iris-setosa           1.4          0.2           4.9          3.0      4.031129        False
  3     Iris-setosa           1.3          0.2           4.7          3.2      4.207137        False
  4     Iris-setosa           1.5          0.2           4.6          3.1      4.062019        False
  5     Iris-setosa           1.4          0.2           5.0          3.6      4.060788        False
  6     Iris-setosa           1.7          0.4           5.4          3.9      3.674235        False
  7     Iris-setosa           1.4          0.3           4.6          3.4      4.170132        False
  8     Iris-setosa           1.5          0.2           5.0          3.4      3.964846        False
 10     Iris-setosa           1.5          0.1           4.9          3.1      3.987480        False
 11     Iris-setosa           1.5          0.2           5.4          3.7      3.885872        False
 12     Iris-setosa           1.6          0.2           4.8          3.4      3.954744        False
 13     Iris-setosa           1.4          0.1           4.8          3.0      4.102438        False
 14     Iris-setosa           1.1          0.1           4.3          3.0      4.548626        False
 15     Iris-setosa           1.2          0.2           5.8          4.0      4.164133        False
 16     Iris-setosa           1.5          0.4           5.7          4.4      3.957272        False
 17     Iris-setosa           1.3          0.4           5.4          3.9      4.027406        False
 18     Iris-setosa           1.4          0.3           5.1          3.5      3.974921        False
 19     Iris-setosa           1.7          0.3           5.7          3.8      3.645545        False
 20     Iris-setosa           1.5          0.3           5.1          3.8      3.930649        False
 21     Iris-setosa           1.7          0.2           5.4          3.4      3.667424        False
 23     Iris-setosa           1.0          0.2           4.6          3.6      4.582576        False
 24     Iris-setosa           1.7          0.5           5.1          3.3      3.649658        False
 25     Iris-setosa           1.9          0.2           4.8          3.4      3.708099        False
 26     Iris-setosa           1.6          0.2           5.0          3.0      3.828838        False
 27     Iris-setosa           1.6          0.4           5.0          3.4      3.820995        False
 29     Iris-setosa           1.4          0.2           5.2          3.4      3.972405        False
 30     Iris-setosa           1.6          0.2           4.7          3.2      3.953479        False
 31     Iris-setosa           1.6          0.2           4.8          3.1      3.897435        False
 32     Iris-setosa           1.5          0.4           5.4          3.4      3.764306        False
 33     Iris-setosa           1.5          0.1           5.2          4.1      4.058325        False
 34     Iris-setosa           1.4          0.2           5.5          4.2      4.075537        False
 35     Iris-setosa           1.5          0.1           4.9          3.1      3.987480        False
 36     Iris-setosa           1.2          0.2           5.0          3.2      4.190465        False
 37     Iris-setosa           1.3          0.2           5.5          3.5      4.016217        False
 38     Iris-setosa           1.5          0.1           4.9          3.1      3.987480        False
 39     Iris-setosa           1.3          0.2           4.4          3.0      4.306971        False
 41     Iris-setosa           1.3          0.3           5.0          3.5      4.106093        False
 42     Iris-setosa           1.3          0.3           4.5          2.3      4.249706        False
 43     Iris-setosa           1.3          0.2           4.4          3.2      4.330127        False
 44     Iris-setosa           1.6          0.6           5.0          3.5      3.786819        False
 45     Iris-setosa           1.9          0.4           5.1          3.8      3.579106        False
 46     Iris-setosa           1.4          0.3           4.8          3.0      4.023680        False
 47     Iris-setosa           1.6          0.2           5.1          3.8      3.884585        False
 48     Iris-setosa           1.4          0.2           4.6          3.2      4.161730        False
 49     Iris-setosa           1.5          0.2           5.3          3.7      3.905125        False
 51 Iris-versicolor           4.7          1.4           7.0          3.2      3.069202        False
 52 Iris-versicolor           4.5          1.5           6.4          3.2      3.165438        False
 53 Iris-versicolor           4.9          1.5           6.9          3.1      2.875761        False
 54 Iris-versicolor           4.0          1.3           5.5          2.3      2.846050        False
 55 Iris-versicolor           4.6          1.5           6.5          2.8      3.269557        False
 56 Iris-versicolor           4.5          1.3           5.7          2.8      3.082207        False
 58 Iris-versicolor           3.3          1.0           4.9          2.4      2.412468        False
 59 Iris-versicolor           4.6          1.3           6.6          2.9      3.272614        False
 60 Iris-versicolor           3.9          1.4           5.2          2.7      2.716616        False
 61 Iris-versicolor           3.5          1.0           5.0          2.0      2.714774        False
 62 Iris-versicolor           4.2          1.5           5.9          3.0      2.893095        False
 63 Iris-versicolor           4.0          1.0           6.0          2.2      2.900000        False
 65 Iris-versicolor           3.6          1.3           5.6          2.9      2.519921        False
 66 Iris-versicolor           4.4          1.4           6.7          3.1      3.160696        False
 67 Iris-versicolor           4.5          1.5           5.6          3.0      3.119295        False
 68 Iris-versicolor           4.1          1.0           5.8          2.7      2.773085        False
 69 Iris-versicolor           4.5          1.5           6.2          2.2      3.355592        False
 70 Iris-versicolor           3.9          1.1           5.6          2.5      2.707397        False
 71 Iris-versicolor           4.8          1.8           5.9          3.2      3.358571        False
 72 Iris-versicolor           4.0          1.3           6.1          2.8      2.774887        False
 73 Iris-versicolor           4.9          1.5           6.3          2.5      3.096773        False
 75 Iris-versicolor           4.3          1.3           6.4          2.9      3.011644        False
 76 Iris-versicolor           4.4          1.4           6.6          3.0      3.154362        False
 78 Iris-versicolor           5.0          1.7           6.7          3.0      2.808914        False
 79 Iris-versicolor           4.5          1.5           6.0          2.9      3.096773        False
 80 Iris-versicolor           3.5          1.0           5.7          2.6      2.459675        False
 81 Iris-versicolor           3.8          1.1           5.5          2.4      2.672078        False
 82 Iris-versicolor           3.7          1.0           5.5          2.4      2.574879        False
 83 Iris-versicolor           3.9          1.2           5.8          2.7      2.655184        False
 84 Iris-versicolor           5.1          1.6           6.0          2.7      3.051229        False
 85 Iris-versicolor           4.5          1.5           5.4          3.0      3.103224        False
 86 Iris-versicolor           4.5          1.6           6.0          3.4      3.127299        False
 87 Iris-versicolor           4.7          1.5           6.7          3.1      3.122499        False
 88 Iris-versicolor           4.4          1.3           6.3          2.3      3.220248        False
 90 Iris-versicolor           4.0          1.3           5.5          2.5      2.796426        False
 91 Iris-versicolor           4.4          1.2           5.5          2.6      3.041381        False
 92 Iris-versicolor           4.6          1.4           6.1          3.0      3.151190        False
 93 Iris-versicolor           4.0          1.2           5.8          2.6      2.751363        False
 94 Iris-versicolor           3.3          1.0           5.0          2.3      2.447448        False
 95 Iris-versicolor           4.2          1.3           5.6          2.7      2.901724        False
 96 Iris-versicolor           4.2          1.2           5.7          3.0      2.791057        False
 97 Iris-versicolor           4.2          1.3           5.7          2.9      2.839014        False
 98 Iris-versicolor           4.3          1.3           6.2          2.9      2.969848        False
 99 Iris-versicolor           3.0          1.1           5.1          2.5      2.362202        False
100 Iris-versicolor           4.1          1.3           5.7          2.8      2.785678        False
102  Iris-virginica           5.1          1.9           5.8          2.7      3.143247        False
103  Iris-virginica           5.9          2.1           7.1          3.0      3.695944        False
104  Iris-virginica           5.6          1.8           6.3          2.9      2.974895        False
105  Iris-virginica           5.8          2.2           6.5          3.0      3.355592        False
106  Iris-virginica           6.6          2.1           7.6          3.0      4.523273        False
107  Iris-virginica           4.5          1.7           4.9          2.5      3.304542        False
108  Iris-virginica           6.3          1.8           7.3          2.9      4.047221        False
109  Iris-virginica           5.8          1.8           6.7          2.5      3.300000        False
110  Iris-virginica           6.1          2.5           7.2          3.6      4.146082        False
111  Iris-virginica           5.1          2.0           6.5          3.2      2.801785        False
112  Iris-virginica           5.3          1.9           6.4          2.7      2.767671        False
113  Iris-virginica           5.5          2.1           6.8          3.0      3.223352        False
114  Iris-virginica           5.0          2.0           5.7          2.5      3.293934        False
116  Iris-virginica           5.3          2.3           6.4          3.2      2.984962        False
117  Iris-virginica           5.5          1.8           6.5          3.0      2.991655        False
118  Iris-virginica           6.7          2.2           7.7          3.8      4.832184        False
119  Iris-virginica           6.9          2.3           7.7          2.6      4.839421        False
120  Iris-virginica           5.0          1.5           6.0          2.2      3.203123        False
123  Iris-virginica           7.6          2.0           7.7          2.8      5.368426        False
124  Iris-virginica           4.9          1.8           6.3          2.7      3.049590        False
125  Iris-virginica           5.7          2.1           6.7          3.3      3.389690        False
126  Iris-virginica           6.0          1.8           7.2          3.2      3.793415        False
127  Iris-virginica           4.8          1.8           6.2          2.8      3.182766        False
128  Iris-virginica           4.9          1.8           6.1          3.0      3.151190        False
129  Iris-virginica           5.6          2.1           6.4          2.8      3.088689        False
130  Iris-virginica           5.8          1.6           7.2          3.0      3.570714        False
131  Iris-virginica           6.1          1.9           7.4          2.8      3.953479        False
132  Iris-virginica           6.4          2.0           7.9          3.8      4.679744        False
133  Iris-virginica           5.6          2.2           6.4          2.8      3.122499        False
134  Iris-virginica           5.1          1.5           6.3          2.8      2.908608        False
135  Iris-virginica           5.6          1.4           6.1          2.6      2.803569        False
137  Iris-virginica           5.6          2.4           6.3          3.4      3.271085        False
138  Iris-virginica           5.5          1.8           6.4          3.1      2.964793        False
139  Iris-virginica           4.8          1.8           6.0          3.0      3.287856        False
140  Iris-virginica           5.4          2.1           6.9          3.1      3.218695        False
141  Iris-virginica           5.6          2.4           6.7          3.1      3.371943        False
142  Iris-virginica           5.1          2.3           6.9          3.1      3.074085        False
143  Iris-virginica           5.1          1.9           5.8          2.7      3.143247        False
144  Iris-virginica           5.9          2.3           6.8          3.2      3.637307        False
145  Iris-virginica           5.7          2.5           6.7          3.3      3.528456        False
146  Iris-virginica           5.2          2.3           6.7          3.0      3.014963        False
147  Iris-virginica           5.0          1.9           6.3          2.5      2.969848        False
148  Iris-virginica           5.2          2.0           6.5          3.0      2.803569        False
149  Iris-virginica           5.4          2.3           6.2          3.4      3.036445        False
150  Iris-virginica           5.1          1.8           5.9          3.0      3.093542        False

Jumlah data setelah outlier dihapus: 135
</pre></div>
</div>
<img alt="_images/dab4a30ae664d7668f8263705370f3e5cb7f5f30ff8e7acdb440e44ca9b8e3d8.png" src="_images/dab4a30ae664d7668f8263705370f3e5cb7f5f30ff8e7acdb440e44ca9b8e3d8.png" />
<img alt="_images/e2f90deea3f7e694545d4dbd664ec6d9a31a30617afd9cbcd285ee43f8648f27.png" src="_images/e2f90deea3f7e694545d4dbd664ec6d9a31a30617afd9cbcd285ee43f8648f27.png" />
</div>
</div>
</section>
<section id="pemisah-outlier-dari-data">
<h2>Pemisah Outlier dari data<a class="headerlink" href="#pemisah-outlier-dari-data" title="Link to this heading">#</a></h2>
<p>Kode dibawah digunakan untuk mendeteksi outlier dalam dataset yang diperoleh dari dua database berbeda, yaitu PostgreSQL dan MySQL. Pertama, program menghubungkan ke masing-masing database menggunakan psycopg2 dan pymysql, lalu mengambil data dari tabel tabel_b di PostgreSQL dan tabel_a di MySQL. Data yang diperoleh kemudian dikonversi menjadi dataframe pandas dan digabungkan berdasarkan kolom “id” dan “class” menggunakan metode inner join, sehingga hanya data yang memiliki kesamaan pada kedua kolom tersebut yang disertakan dalam hasil akhir.</p>
<p>Selanjutnya, dari data yang telah digabungkan, hanya empat fitur numerik yaitu “petal_length”, “petal_width”, “sepal_length”, dan “sepal_width” yang digunakan untuk analisis. Data ini diekstrak dalam bentuk array dan kemudian diproses menggunakan Local Outlier Factor (LOF) dengan parameter n_neighbors=90 untuk mendeteksi outlier. Model LOF memberikan label 1 untuk data normal dan -1 untuk data yang dianggap sebagai outlier, lalu hasilnya ditambahkan sebagai kolom baru dalam dataframe.</p>
<p>Setelah proses deteksi selesai, program mencetak seluruh data dengan label outlier, jumlah total outlier yang terdeteksi, serta data yang dianggap normal setelah menghapus outlier. Data yang tidak termasuk outlier disimpan dalam dataframe baru dengan kolom “outlier_label” dihapus, sehingga hanya menyisakan informasi yang relevan. Akhirnya, program menampilkan jumlah total data setelah penghapusan outlier dan mencetak seluruh data yang dianggap normal untuk dianalisis lebih lanjut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">psycopg2</span>
<span class="kn">import</span> <span class="nn">pymysql</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span> <span class="p">,</span> <span class="n">KFold</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">LocalOutlierFactor</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">LabelEncoder</span><span class="p">,</span> <span class="n">Normalizer</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">classification_report</span>
<span class="kn">from</span> <span class="nn">sklearn.inspection</span> <span class="kn">import</span> <span class="n">DecisionBoundaryDisplay</span>

<span class="k">def</span> <span class="nf">get_pg_data</span><span class="p">():</span>
    <span class="n">conn</span> <span class="o">=</span> <span class="n">psycopg2</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span>
        <span class="n">host</span><span class="o">=</span><span class="s2">&quot;pg-1d952496-dinaaa-269a.i.aivencloud.com&quot;</span><span class="p">,</span>
        <span class="n">user</span><span class="o">=</span><span class="s2">&quot;avnadmin&quot;</span><span class="p">,</span>
        <span class="n">password</span><span class="o">=</span><span class="s2">&quot;AVNS_n1Ru1Ddse4sg_Gpi7Nb&quot;</span><span class="p">,</span>
        <span class="n">database</span><span class="o">=</span><span class="s2">&quot;defaultdb&quot;</span><span class="p">,</span>
        <span class="n">port</span><span class="o">=</span><span class="mi">27730</span>
    <span class="p">)</span>
    <span class="n">cursor</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">cursor</span><span class="p">()</span>
    <span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;SELECT * FROM tabel_b&quot;</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">cursor</span><span class="o">.</span><span class="n">fetchall</span><span class="p">()</span>
    <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">desc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">desc</span> <span class="ow">in</span> <span class="n">cursor</span><span class="o">.</span><span class="n">description</span><span class="p">]</span>
    <span class="n">cursor</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="n">conn</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_mysql_data</span><span class="p">():</span>
    <span class="n">conn</span> <span class="o">=</span> <span class="n">pymysql</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span>
        <span class="n">host</span><span class="o">=</span><span class="s2">&quot;mysql-e89c328-dinaaa-269a.i.aivencloud.com&quot;</span><span class="p">,</span>
        <span class="n">user</span><span class="o">=</span><span class="s2">&quot;avnadmin&quot;</span><span class="p">,</span>
        <span class="n">password</span><span class="o">=</span><span class="s2">&quot;AVNS_GBbKfVRE1qvWkI6gU2s&quot;</span><span class="p">,</span>
        <span class="n">database</span><span class="o">=</span><span class="s2">&quot;iris_mysql&quot;</span><span class="p">,</span>
        <span class="n">port</span><span class="o">=</span><span class="mi">27730</span>
    <span class="p">)</span>
    <span class="n">cursor</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">cursor</span><span class="p">()</span>
    <span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;SELECT * FROM tabel_a&quot;</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">cursor</span><span class="o">.</span><span class="n">fetchall</span><span class="p">()</span>
    <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">desc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">desc</span> <span class="ow">in</span> <span class="n">cursor</span><span class="o">.</span><span class="n">description</span><span class="p">]</span>
    <span class="n">cursor</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="n">conn</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">)</span>

<span class="c1"># Ambil data dari kedua database</span>
<span class="n">df_postgresql</span> <span class="o">=</span> <span class="n">get_pg_data</span><span class="p">()</span>
<span class="n">df_mysql</span> <span class="o">=</span> <span class="n">get_mysql_data</span><span class="p">()</span>

<span class="c1"># Gabungkan berdasarkan kolom &#39;id&#39; dan &#39;class&#39;</span>
<span class="n">df_merge</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">df_mysql</span><span class="p">,</span> <span class="n">df_postgresql</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;class&quot;</span><span class="p">],</span> <span class="n">how</span><span class="o">=</span><span class="s2">&quot;inner&quot;</span><span class="p">)</span>

<span class="c1"># Ambil data fitur numerik tanpa kolom &#39;class&#39;</span>
<span class="n">feature_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;petal_length&quot;</span><span class="p">,</span> <span class="s2">&quot;petal_width&quot;</span><span class="p">,</span> <span class="s2">&quot;sepal_length&quot;</span><span class="p">,</span> <span class="s2">&quot;sepal_width&quot;</span><span class="p">]</span>
<span class="n">data_values</span> <span class="o">=</span> <span class="n">df_merge</span><span class="p">[</span><span class="n">feature_columns</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># Inisialisasi model LOF</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">LocalOutlierFactor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">data_values</span><span class="p">)</span>

<span class="c1"># Tambahkan hasil label ke dataframe</span>
<span class="n">df_merge</span><span class="p">[</span><span class="s2">&quot;outlier_label&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">label</span>

<span class="c1"># Cetak hasil dengan ID dan class</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_merge</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>

<span class="n">num_outliers</span> <span class="o">=</span> <span class="p">(</span><span class="n">label</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Jumlah outlier: </span><span class="si">{</span><span class="n">num_outliers</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">df_filtered</span> <span class="o">=</span> <span class="n">df_merge</span><span class="p">[</span><span class="n">label</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;outlier_label&quot;</span><span class="p">],</span> <span class="n">errors</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="n">outliers</span> <span class="o">=</span> <span class="n">df_merge</span><span class="p">[</span><span class="n">label</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;outlier_label&quot;</span><span class="p">],</span> <span class="n">errors</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Data Outlier:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">outliers</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Jumlah data setelah dihapus : &quot;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">df_filtered</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Data tidak outlier :&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_filtered</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> id           class  petal_length  petal_width  sepal_length  sepal_width  outlier_label
  1     Iris-setosa           1.4          0.2           5.1          3.5              1
  2     Iris-setosa           1.4          0.2           4.9          3.0              1
  3     Iris-setosa           1.3          0.2           4.7          3.2              1
  4     Iris-setosa           1.5          0.2           4.6          3.1              1
  5     Iris-setosa           1.4          0.2           5.0          3.6              1
  6     Iris-setosa           1.7          0.4           5.4          3.9              1
  7     Iris-setosa           1.4          0.3           4.6          3.4              1
  8     Iris-setosa           1.5          0.2           5.0          3.4              1
  9     Iris-setosa          60.0         43.0          40.0         57.0             -1
 10     Iris-setosa           1.5          0.1           4.9          3.1              1
 11     Iris-setosa           1.5          0.2           5.4          3.7              1
 12     Iris-setosa           1.6          0.2           4.8          3.4              1
 13     Iris-setosa           1.4          0.1           4.8          3.0              1
 14     Iris-setosa           1.1          0.1           4.3          3.0              1
 15     Iris-setosa           1.2          0.2           5.8          4.0              1
 16     Iris-setosa           1.5          0.4           5.7          4.4              1
 17     Iris-setosa           1.3          0.4           5.4          3.9              1
 18     Iris-setosa           1.4          0.3           5.1          3.5              1
 19     Iris-setosa           1.7          0.3           5.7          3.8              1
 20     Iris-setosa           1.5          0.3           5.1          3.8              1
 21     Iris-setosa           1.7          0.2           5.4          3.4              1
 22     Iris-setosa          67.0         76.0          56.0         45.0             -1
 23     Iris-setosa           1.0          0.2           4.6          3.6              1
 24     Iris-setosa           1.7          0.5           5.1          3.3              1
 25     Iris-setosa           1.9          0.2           4.8          3.4              1
 26     Iris-setosa           1.6          0.2           5.0          3.0              1
 27     Iris-setosa           1.6          0.4           5.0          3.4              1
 28     Iris-setosa          78.0         38.0          87.0         35.0             -1
 29     Iris-setosa           1.4          0.2           5.2          3.4              1
 30     Iris-setosa           1.6          0.2           4.7          3.2              1
 31     Iris-setosa           1.6          0.2           4.8          3.1              1
 32     Iris-setosa           1.5          0.4           5.4          3.4              1
 33     Iris-setosa           1.5          0.1           5.2          4.1              1
 34     Iris-setosa           1.4          0.2           5.5          4.2              1
 35     Iris-setosa           1.5          0.1           4.9          3.1              1
 36     Iris-setosa           1.2          0.2           5.0          3.2              1
 37     Iris-setosa           1.3          0.2           5.5          3.5              1
 38     Iris-setosa           1.5          0.1           4.9          3.1              1
 39     Iris-setosa           1.3          0.2           4.4          3.0              1
 40     Iris-setosa          96.0         55.0          77.0         56.0             -1
 41     Iris-setosa           1.3          0.3           5.0          3.5              1
 42     Iris-setosa           1.3          0.3           4.5          2.3              1
 43     Iris-setosa           1.3          0.2           4.4          3.2              1
 44     Iris-setosa           1.6          0.6           5.0          3.5              1
 45     Iris-setosa           1.9          0.4           5.1          3.8              1
 46     Iris-setosa           1.4          0.3           4.8          3.0              1
 47     Iris-setosa           1.6          0.2           5.1          3.8              1
 48     Iris-setosa           1.4          0.2           4.6          3.2              1
 49     Iris-setosa           1.5          0.2           5.3          3.7              1
 50     Iris-setosa          63.0         39.0          66.0         41.0             -1
 51 Iris-versicolor           4.7          1.4           7.0          3.2              1
 52 Iris-versicolor           4.5          1.5           6.4          3.2              1
 53 Iris-versicolor           4.9          1.5           6.9          3.1              1
 54 Iris-versicolor           4.0          1.3           5.5          2.3              1
 55 Iris-versicolor           4.6          1.5           6.5          2.8              1
 56 Iris-versicolor           4.5          1.3           5.7          2.8              1
 57 Iris-versicolor          40.0         61.0          68.0         35.0             -1
 58 Iris-versicolor           3.3          1.0           4.9          2.4              1
 59 Iris-versicolor           4.6          1.3           6.6          2.9              1
 60 Iris-versicolor           3.9          1.4           5.2          2.7              1
 61 Iris-versicolor           3.5          1.0           5.0          2.0              1
 62 Iris-versicolor           4.2          1.5           5.9          3.0              1
 63 Iris-versicolor           4.0          1.0           6.0          2.2              1
 64 Iris-versicolor          47.0         61.0          61.0         29.0             -1
 65 Iris-versicolor           3.6          1.3           5.6          2.9              1
 66 Iris-versicolor           4.4          1.4           6.7          3.1              1
 67 Iris-versicolor           4.5          1.5           5.6          3.0              1
 68 Iris-versicolor           4.1          1.0           5.8          2.7              1
 69 Iris-versicolor           4.5          1.5           6.2          2.2              1
 70 Iris-versicolor           3.9          1.1           5.6          2.5              1
 71 Iris-versicolor           4.8          1.8           5.9          3.2              1
 72 Iris-versicolor           4.0          1.3           6.1          2.8              1
 73 Iris-versicolor           4.9          1.5           6.3          2.5              1
 74 Iris-versicolor          87.0         67.0          61.0         46.0             -1
 75 Iris-versicolor           4.3          1.3           6.4          2.9              1
 76 Iris-versicolor           4.4          1.4           6.6          3.0              1
 77 Iris-versicolor          74.0         96.0          68.0         58.0             -1
 78 Iris-versicolor           5.0          1.7           6.7          3.0              1
 79 Iris-versicolor           4.5          1.5           6.0          2.9              1
 80 Iris-versicolor           3.5          1.0           5.7          2.6              1
 81 Iris-versicolor           3.8          1.1           5.5          2.4              1
 82 Iris-versicolor           3.7          1.0           5.5          2.4              1
 83 Iris-versicolor           3.9          1.2           5.8          2.7              1
 84 Iris-versicolor           5.1          1.6           6.0          2.7              1
 85 Iris-versicolor           4.5          1.5           5.4          3.0              1
 86 Iris-versicolor           4.5          1.6           6.0          3.4              1
 87 Iris-versicolor           4.7          1.5           6.7          3.1              1
 88 Iris-versicolor           4.4          1.3           6.3          2.3              1
 89 Iris-versicolor          86.0         46.0          56.0         89.0             -1
 90 Iris-versicolor           4.0          1.3           5.5          2.5              1
 91 Iris-versicolor           4.4          1.2           5.5          2.6              1
 92 Iris-versicolor           4.6          1.4           6.1          3.0              1
 93 Iris-versicolor           4.0          1.2           5.8          2.6              1
 94 Iris-versicolor           3.3          1.0           5.0          2.3              1
 95 Iris-versicolor           4.2          1.3           5.6          2.7              1
 96 Iris-versicolor           4.2          1.2           5.7          3.0              1
 97 Iris-versicolor           4.2          1.3           5.7          2.9              1
 98 Iris-versicolor           4.3          1.3           6.2          2.9              1
 99 Iris-versicolor           3.0          1.1           5.1          2.5              1
100 Iris-versicolor           4.1          1.3           5.7          2.8              1
101  Iris-virginica          60.0         36.0          75.0         36.0             -1
102  Iris-virginica           5.1          1.9           5.8          2.7              1
103  Iris-virginica           5.9          2.1           7.1          3.0              1
104  Iris-virginica           5.6          1.8           6.3          2.9              1
105  Iris-virginica           5.8          2.2           6.5          3.0              1
106  Iris-virginica           6.6          2.1           7.6          3.0              1
107  Iris-virginica           4.5          1.7           4.9          2.5              1
108  Iris-virginica           6.3          1.8           7.3          2.9              1
109  Iris-virginica           5.8          1.8           6.7          2.5              1
110  Iris-virginica           6.1          2.5           7.2          3.6              1
111  Iris-virginica           5.1          2.0           6.5          3.2              1
112  Iris-virginica           5.3          1.9           6.4          2.7              1
113  Iris-virginica           5.5          2.1           6.8          3.0              1
114  Iris-virginica           5.0          2.0           5.7          2.5              1
115  Iris-virginica          51.0         42.0          58.0         82.0             -1
116  Iris-virginica           5.3          2.3           6.4          3.2              1
117  Iris-virginica           5.5          1.8           6.5          3.0              1
118  Iris-virginica           6.7          2.2           7.7          3.8              1
119  Iris-virginica           6.9          2.3           7.7          2.6              1
120  Iris-virginica           5.0          1.5           6.0          2.2              1
121  Iris-virginica          57.0         32.0          69.0         39.0             -1
122  Iris-virginica          94.0         67.0          56.0         98.0             -1
123  Iris-virginica           7.6          2.0           7.7          2.8              1
124  Iris-virginica           4.9          1.8           6.3          2.7              1
125  Iris-virginica           5.7          2.1           6.7          3.3              1
126  Iris-virginica           6.0          1.8           7.2          3.2              1
127  Iris-virginica           4.8          1.8           6.2          2.8              1
128  Iris-virginica           4.9          1.8           6.1          3.0              1
129  Iris-virginica           5.6          2.1           6.4          2.8              1
130  Iris-virginica           5.8          1.6           7.2          3.0              1
131  Iris-virginica           6.1          1.9           7.4          2.8              1
132  Iris-virginica           6.4          2.0           7.9          3.8              1
133  Iris-virginica           5.6          2.2           6.4          2.8              1
134  Iris-virginica           5.1          1.5           6.3          2.8              1
135  Iris-virginica           5.6          1.4           6.1          2.6              1
136  Iris-virginica          71.0         65.0          77.0         38.0             -1
137  Iris-virginica           5.6          2.4           6.3          3.4              1
138  Iris-virginica           5.5          1.8           6.4          3.1              1
139  Iris-virginica           4.8          1.8           6.0          3.0              1
140  Iris-virginica           5.4          2.1           6.9          3.1              1
141  Iris-virginica           5.6          2.4           6.7          3.1              1
142  Iris-virginica           5.1          2.3           6.9          3.1              1
143  Iris-virginica           5.1          1.9           5.8          2.7              1
144  Iris-virginica           5.9          2.3           6.8          3.2              1
145  Iris-virginica           5.7          2.5           6.7          3.3              1
146  Iris-virginica           5.2          2.3           6.7          3.0              1
147  Iris-virginica           5.0          1.9           6.3          2.5              1
148  Iris-virginica           5.2          2.0           6.5          3.0              1
149  Iris-virginica           5.4          2.3           6.2          3.4              1
150  Iris-virginica           5.1          1.8           5.9          3.0              1

Jumlah outlier: 15

Data Outlier:
 id           class  petal_length  petal_width  sepal_length  sepal_width
  9     Iris-setosa          60.0         43.0          40.0         57.0
 22     Iris-setosa          67.0         76.0          56.0         45.0
 28     Iris-setosa          78.0         38.0          87.0         35.0
 40     Iris-setosa          96.0         55.0          77.0         56.0
 50     Iris-setosa          63.0         39.0          66.0         41.0
 57 Iris-versicolor          40.0         61.0          68.0         35.0
 64 Iris-versicolor          47.0         61.0          61.0         29.0
 74 Iris-versicolor          87.0         67.0          61.0         46.0
 77 Iris-versicolor          74.0         96.0          68.0         58.0
 89 Iris-versicolor          86.0         46.0          56.0         89.0
101  Iris-virginica          60.0         36.0          75.0         36.0
115  Iris-virginica          51.0         42.0          58.0         82.0
121  Iris-virginica          57.0         32.0          69.0         39.0
122  Iris-virginica          94.0         67.0          56.0         98.0
136  Iris-virginica          71.0         65.0          77.0         38.0

Jumlah data setelah dihapus :  135

Data tidak outlier :
 id           class  petal_length  petal_width  sepal_length  sepal_width
  1     Iris-setosa           1.4          0.2           5.1          3.5
  2     Iris-setosa           1.4          0.2           4.9          3.0
  3     Iris-setosa           1.3          0.2           4.7          3.2
  4     Iris-setosa           1.5          0.2           4.6          3.1
  5     Iris-setosa           1.4          0.2           5.0          3.6
  6     Iris-setosa           1.7          0.4           5.4          3.9
  7     Iris-setosa           1.4          0.3           4.6          3.4
  8     Iris-setosa           1.5          0.2           5.0          3.4
 10     Iris-setosa           1.5          0.1           4.9          3.1
 11     Iris-setosa           1.5          0.2           5.4          3.7
 12     Iris-setosa           1.6          0.2           4.8          3.4
 13     Iris-setosa           1.4          0.1           4.8          3.0
 14     Iris-setosa           1.1          0.1           4.3          3.0
 15     Iris-setosa           1.2          0.2           5.8          4.0
 16     Iris-setosa           1.5          0.4           5.7          4.4
 17     Iris-setosa           1.3          0.4           5.4          3.9
 18     Iris-setosa           1.4          0.3           5.1          3.5
 19     Iris-setosa           1.7          0.3           5.7          3.8
 20     Iris-setosa           1.5          0.3           5.1          3.8
 21     Iris-setosa           1.7          0.2           5.4          3.4
 23     Iris-setosa           1.0          0.2           4.6          3.6
 24     Iris-setosa           1.7          0.5           5.1          3.3
 25     Iris-setosa           1.9          0.2           4.8          3.4
 26     Iris-setosa           1.6          0.2           5.0          3.0
 27     Iris-setosa           1.6          0.4           5.0          3.4
 29     Iris-setosa           1.4          0.2           5.2          3.4
 30     Iris-setosa           1.6          0.2           4.7          3.2
 31     Iris-setosa           1.6          0.2           4.8          3.1
 32     Iris-setosa           1.5          0.4           5.4          3.4
 33     Iris-setosa           1.5          0.1           5.2          4.1
 34     Iris-setosa           1.4          0.2           5.5          4.2
 35     Iris-setosa           1.5          0.1           4.9          3.1
 36     Iris-setosa           1.2          0.2           5.0          3.2
 37     Iris-setosa           1.3          0.2           5.5          3.5
 38     Iris-setosa           1.5          0.1           4.9          3.1
 39     Iris-setosa           1.3          0.2           4.4          3.0
 41     Iris-setosa           1.3          0.3           5.0          3.5
 42     Iris-setosa           1.3          0.3           4.5          2.3
 43     Iris-setosa           1.3          0.2           4.4          3.2
 44     Iris-setosa           1.6          0.6           5.0          3.5
 45     Iris-setosa           1.9          0.4           5.1          3.8
 46     Iris-setosa           1.4          0.3           4.8          3.0
 47     Iris-setosa           1.6          0.2           5.1          3.8
 48     Iris-setosa           1.4          0.2           4.6          3.2
 49     Iris-setosa           1.5          0.2           5.3          3.7
 51 Iris-versicolor           4.7          1.4           7.0          3.2
 52 Iris-versicolor           4.5          1.5           6.4          3.2
 53 Iris-versicolor           4.9          1.5           6.9          3.1
 54 Iris-versicolor           4.0          1.3           5.5          2.3
 55 Iris-versicolor           4.6          1.5           6.5          2.8
 56 Iris-versicolor           4.5          1.3           5.7          2.8
 58 Iris-versicolor           3.3          1.0           4.9          2.4
 59 Iris-versicolor           4.6          1.3           6.6          2.9
 60 Iris-versicolor           3.9          1.4           5.2          2.7
 61 Iris-versicolor           3.5          1.0           5.0          2.0
 62 Iris-versicolor           4.2          1.5           5.9          3.0
 63 Iris-versicolor           4.0          1.0           6.0          2.2
 65 Iris-versicolor           3.6          1.3           5.6          2.9
 66 Iris-versicolor           4.4          1.4           6.7          3.1
 67 Iris-versicolor           4.5          1.5           5.6          3.0
 68 Iris-versicolor           4.1          1.0           5.8          2.7
 69 Iris-versicolor           4.5          1.5           6.2          2.2
 70 Iris-versicolor           3.9          1.1           5.6          2.5
 71 Iris-versicolor           4.8          1.8           5.9          3.2
 72 Iris-versicolor           4.0          1.3           6.1          2.8
 73 Iris-versicolor           4.9          1.5           6.3          2.5
 75 Iris-versicolor           4.3          1.3           6.4          2.9
 76 Iris-versicolor           4.4          1.4           6.6          3.0
 78 Iris-versicolor           5.0          1.7           6.7          3.0
 79 Iris-versicolor           4.5          1.5           6.0          2.9
 80 Iris-versicolor           3.5          1.0           5.7          2.6
 81 Iris-versicolor           3.8          1.1           5.5          2.4
 82 Iris-versicolor           3.7          1.0           5.5          2.4
 83 Iris-versicolor           3.9          1.2           5.8          2.7
 84 Iris-versicolor           5.1          1.6           6.0          2.7
 85 Iris-versicolor           4.5          1.5           5.4          3.0
 86 Iris-versicolor           4.5          1.6           6.0          3.4
 87 Iris-versicolor           4.7          1.5           6.7          3.1
 88 Iris-versicolor           4.4          1.3           6.3          2.3
 90 Iris-versicolor           4.0          1.3           5.5          2.5
 91 Iris-versicolor           4.4          1.2           5.5          2.6
 92 Iris-versicolor           4.6          1.4           6.1          3.0
 93 Iris-versicolor           4.0          1.2           5.8          2.6
 94 Iris-versicolor           3.3          1.0           5.0          2.3
 95 Iris-versicolor           4.2          1.3           5.6          2.7
 96 Iris-versicolor           4.2          1.2           5.7          3.0
 97 Iris-versicolor           4.2          1.3           5.7          2.9
 98 Iris-versicolor           4.3          1.3           6.2          2.9
 99 Iris-versicolor           3.0          1.1           5.1          2.5
100 Iris-versicolor           4.1          1.3           5.7          2.8
102  Iris-virginica           5.1          1.9           5.8          2.7
103  Iris-virginica           5.9          2.1           7.1          3.0
104  Iris-virginica           5.6          1.8           6.3          2.9
105  Iris-virginica           5.8          2.2           6.5          3.0
106  Iris-virginica           6.6          2.1           7.6          3.0
107  Iris-virginica           4.5          1.7           4.9          2.5
108  Iris-virginica           6.3          1.8           7.3          2.9
109  Iris-virginica           5.8          1.8           6.7          2.5
110  Iris-virginica           6.1          2.5           7.2          3.6
111  Iris-virginica           5.1          2.0           6.5          3.2
112  Iris-virginica           5.3          1.9           6.4          2.7
113  Iris-virginica           5.5          2.1           6.8          3.0
114  Iris-virginica           5.0          2.0           5.7          2.5
116  Iris-virginica           5.3          2.3           6.4          3.2
117  Iris-virginica           5.5          1.8           6.5          3.0
118  Iris-virginica           6.7          2.2           7.7          3.8
119  Iris-virginica           6.9          2.3           7.7          2.6
120  Iris-virginica           5.0          1.5           6.0          2.2
123  Iris-virginica           7.6          2.0           7.7          2.8
124  Iris-virginica           4.9          1.8           6.3          2.7
125  Iris-virginica           5.7          2.1           6.7          3.3
126  Iris-virginica           6.0          1.8           7.2          3.2
127  Iris-virginica           4.8          1.8           6.2          2.8
128  Iris-virginica           4.9          1.8           6.1          3.0
129  Iris-virginica           5.6          2.1           6.4          2.8
130  Iris-virginica           5.8          1.6           7.2          3.0
131  Iris-virginica           6.1          1.9           7.4          2.8
132  Iris-virginica           6.4          2.0           7.9          3.8
133  Iris-virginica           5.6          2.2           6.4          2.8
134  Iris-virginica           5.1          1.5           6.3          2.8
135  Iris-virginica           5.6          1.4           6.1          2.6
137  Iris-virginica           5.6          2.4           6.3          3.4
138  Iris-virginica           5.5          1.8           6.4          3.1
139  Iris-virginica           4.8          1.8           6.0          3.0
140  Iris-virginica           5.4          2.1           6.9          3.1
141  Iris-virginica           5.6          2.4           6.7          3.1
142  Iris-virginica           5.1          2.3           6.9          3.1
143  Iris-virginica           5.1          1.9           5.8          2.7
144  Iris-virginica           5.9          2.3           6.8          3.2
145  Iris-virginica           5.7          2.5           6.7          3.3
146  Iris-virginica           5.2          2.3           6.7          3.0
147  Iris-virginica           5.0          1.9           6.3          2.5
148  Iris-virginica           5.2          2.0           6.5          3.0
149  Iris-virginica           5.4          2.3           6.2          3.4
150  Iris-virginica           5.1          1.8           5.9          3.0
</pre></div>
</div>
</div>
</div>
</section>
<section id="menghitung-akurasi-data">
<h2>Menghitung akurasi data<a class="headerlink" href="#menghitung-akurasi-data" title="Link to this heading">#</a></h2>
<p>Kode ini bertujuan untuk melakukan deteksi outlier menggunakan Local Outlier Factor (LOF), kemudian melatih model K-Nearest Neighbors (KNN) dengan dan tanpa outlier untuk membandingkan akurasinya.</p>
<p>Pertama, kode mengambil fitur yang digunakan untuk analisis dari dataframe yang telah digabungkan sebelumnya (df_merged). Kolom “class” digunakan sebagai label target, lalu diubah menjadi format numerik menggunakan LabelEncoder().</p>
<p>Selanjutnya, LOF diterapkan dengan n_neighbors=90 dan contamination=0.1 untuk mendeteksi data yang dianggap sebagai outlier. Data yang memiliki label outlier (-1) dipisahkan, sehingga terbentuk dua dataset: satu dengan outlier (df_merged) dan satu tanpa outlier (df_cleaned).</p>
<p>Setelah itu, data dibagi menjadi training set (80%) dan testing set (20%) menggunakan train_test_split(). Pembagian ini dilakukan dua kali, yaitu untuk dataset yang masih mengandung outlier (X_train_all, X_test_all, y_train_all, y_test_all) dan dataset yang telah dibersihkan dari outlier (X_train_clean, X_test_clean, y_train_clean, y_test_clean).</p>
<p>Untuk membangun model, digunakan pipeline yang terdiri dari StandardScaler() untuk normalisasi data dan KNeighborsClassifier(n_neighbors=11) sebagai model klasifikasi. Model KNN pertama kali dilatih menggunakan dataset yang masih mengandung outlier, kemudian dievaluasi menggunakan accuracy_score() dan classification_report(). Hasil akurasi dan laporan klasifikasi ditampilkan untuk melihat performa model.</p>
<p>Selanjutnya, model KNN dilatih ulang menggunakan dataset yang sudah dibersihkan dari outlier, dan dilakukan evaluasi dengan cara yang sama. Akurasi dan laporan klasifikasi setelah pembersihan outlier juga ditampilkan untuk melihat apakah model memiliki performa yang lebih baik setelah outlier dihilangkan.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="n">feature_columns</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span>

<span class="c1"># Encode label kelas ke numerik</span>
<span class="n">label_encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">y_encoded</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># Menerapkan LOF untuk deteksi outlier</span>
<span class="n">lof</span> <span class="o">=</span> <span class="n">LocalOutlierFactor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span> <span class="n">contamination</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">outlier_labels</span> <span class="o">=</span> <span class="n">lof</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;outlier&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">outlier_labels</span>

<span class="c1"># Pisahkan data dengan outlier dan tanpa outlier</span>
<span class="n">df_cleaned</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;outlier&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;outlier&quot;</span><span class="p">])</span>

<span class="c1"># Membagi data menjadi training (80%) dan testing (20%)</span>
<span class="n">X_train_all</span><span class="p">,</span> <span class="n">X_test_all</span><span class="p">,</span> <span class="n">y_train_all</span><span class="p">,</span> <span class="n">y_test_all</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y_encoded</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="n">X_train_clean</span><span class="p">,</span> <span class="n">X_test_clean</span><span class="p">,</span> <span class="n">y_train_clean</span><span class="p">,</span> <span class="n">y_test_clean</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">df_cleaned</span><span class="p">[</span><span class="n">feature_columns</span><span class="p">],</span>
    <span class="n">label_encoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df_cleaned</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]),</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="c1"># Pipeline dengan StandardScaler dan KNN</span>
<span class="n">knn_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
    <span class="p">(</span><span class="s2">&quot;knn&quot;</span><span class="p">,</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">11</span><span class="p">))</span>
<span class="p">])</span>

<span class="c1"># Latih model pada data dengan outlier</span>
<span class="n">knn_pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_all</span><span class="p">,</span> <span class="n">y_train_all</span><span class="p">)</span>
<span class="n">y_pred_all</span> <span class="o">=</span> <span class="n">knn_pipeline</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_all</span><span class="p">)</span>
<span class="n">accuracy_all</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_all</span><span class="p">,</span> <span class="n">y_pred_all</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Akurasi dengan outlier:&quot;</span><span class="p">,</span> <span class="n">accuracy_all</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test_all</span><span class="p">,</span> <span class="n">y_pred_all</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>

<span class="c1"># Latih model pada data tanpa outlier</span>
<span class="n">knn_pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_clean</span><span class="p">,</span> <span class="n">y_train_clean</span><span class="p">)</span>
<span class="n">y_pred_clean</span> <span class="o">=</span> <span class="n">knn_pipeline</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_clean</span><span class="p">)</span>
<span class="n">accuracy_clean</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_clean</span><span class="p">,</span> <span class="n">y_pred_clean</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Akurasi tanpa outlier:&quot;</span><span class="p">,</span> <span class="n">accuracy_clean</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test_clean</span><span class="p">,</span> <span class="n">y_pred_clean</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Akurasi dengan outlier: 0.9
                 precision    recall  f1-score   support

    Iris-setosa       0.77      1.00      0.87        10
Iris-versicolor       1.00      0.67      0.80         9
 Iris-virginica       1.00      1.00      1.00        11

       accuracy                           0.90        30
      macro avg       0.92      0.89      0.89        30
   weighted avg       0.92      0.90      0.90        30

Akurasi tanpa outlier: 0.9629629629629629
                 precision    recall  f1-score   support

    Iris-setosa       1.00      1.00      1.00        12
Iris-versicolor       0.88      1.00      0.93         7
 Iris-virginica       1.00      0.88      0.93         8

       accuracy                           0.96        27
      macro avg       0.96      0.96      0.96        27
   weighted avg       0.97      0.96      0.96        27
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">classification_report</span>
<span class="kn">from</span> <span class="nn">sklearn.inspection</span> <span class="kn">import</span> <span class="n">DecisionBoundaryDisplay</span>

<span class="c1"># Ambil dua fitur utama untuk visualisasi decision boundary</span>
<span class="n">feature_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;petal_length&quot;</span><span class="p">,</span> <span class="s2">&quot;petal_width&quot;</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="n">feature_columns</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span>

<span class="c1"># Encode label kelas ke numerik</span>
<span class="n">label_encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">y_encoded</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>  <span class="c1"># Ubah nama kelas jadi angka</span>

<span class="c1"># Membagi data menjadi training (80%) dan testing (20%)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y_encoded</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="c1"># Pipeline dengan KNN dan StandardScaler</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
    <span class="p">(</span><span class="s2">&quot;knn&quot;</span><span class="p">,</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">11</span><span class="p">))</span>
<span class="p">])</span>

<span class="c1"># Pelatihan model KNN</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Evaluasi model</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Akurasi: </span><span class="si">{</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>

<span class="c1"># Visualisasi Decision Boundary</span>
<span class="n">_</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">weights</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axs</span><span class="p">,</span> <span class="p">(</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span> <span class="s2">&quot;distance&quot;</span><span class="p">)):</span>
    <span class="n">clf</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="n">knn__weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">disp</span> <span class="o">=</span> <span class="n">DecisionBoundaryDisplay</span><span class="o">.</span><span class="n">from_estimator</span><span class="p">(</span>
        <span class="n">clf</span><span class="p">,</span>
        <span class="n">X_test</span><span class="p">,</span>
        <span class="n">response_method</span><span class="o">=</span><span class="s2">&quot;predict&quot;</span><span class="p">,</span>
        <span class="n">plot_method</span><span class="o">=</span><span class="s2">&quot;pcolormesh&quot;</span><span class="p">,</span>
        <span class="n">xlabel</span><span class="o">=</span><span class="n">feature_columns</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">ylabel</span><span class="o">=</span><span class="n">feature_columns</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">shading</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">scatter</span> <span class="o">=</span> <span class="n">disp</span><span class="o">.</span><span class="n">ax_</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
        <span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="n">c</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;viridis&quot;</span>
    <span class="p">)</span>
    <span class="n">disp</span><span class="o">.</span><span class="n">ax_</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span>
        <span class="n">scatter</span><span class="o">.</span><span class="n">legend_elements</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span>
        <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower left&quot;</span><span class="p">,</span>
        <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Classes&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">disp</span><span class="o">.</span><span class="n">ax_</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;3-Class classification</span><span class="se">\n</span><span class="s2">(k=</span><span class="si">{</span><span class="n">clf</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">n_neighbors</span><span class="si">}</span><span class="s2">, weights=</span><span class="si">{</span><span class="n">weights</span><span class="si">!r}</span><span class="s2">)&quot;</span>
    <span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Akurasi: 0.9
                 precision    recall  f1-score   support

    Iris-setosa       0.83      1.00      0.91        10
Iris-versicolor       1.00      0.67      0.80         9
 Iris-virginica       0.92      1.00      0.96        11

       accuracy                           0.90        30
      macro avg       0.92      0.89      0.89        30
   weighted avg       0.91      0.90      0.89        30
</pre></div>
</div>
<img alt="_images/85c39b663e8b244dbc37ab1a743dede7371bf9cc6902640ca5a35a7a08d99436.png" src="_images/85c39b663e8b244dbc37ab1a743dede7371bf9cc6902640ca5a35a7a08d99436.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">psycopg2</span>
<span class="kn">import</span> <span class="nn">pymysql</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">LocalOutlierFactor</span><span class="p">,</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">classification_report</span>
<span class="kn">from</span> <span class="nn">sklearn.inspection</span> <span class="kn">import</span> <span class="n">DecisionBoundaryDisplay</span>


<span class="c1"># Ambil dua fitur utama untuk visualisasi decision boundary</span>
<span class="n">feature_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;sepal_length&quot;</span><span class="p">,</span> <span class="s2">&quot;sepal_width&quot;</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="n">feature_columns</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span>

<span class="c1"># Encode label kelas ke numerik</span>
<span class="n">label_encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">y_encoded</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>  <span class="c1"># Mengubah nama kelas menjadi angka</span>

<span class="c1"># Menerapkan LOF untuk deteksi outlier</span>
<span class="n">lof</span> <span class="o">=</span> <span class="n">LocalOutlierFactor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">contamination</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">outlier_labels</span> <span class="o">=</span> <span class="n">lof</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;outlier&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">outlier_labels</span>

<span class="c1"># Menghapus data yang terdeteksi sebagai outlier</span>
<span class="n">df_cleaned</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;outlier&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;outlier&quot;</span><span class="p">])</span>

<span class="c1"># Membagi data menjadi training (80%) dan testing (20%)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">df_cleaned</span><span class="p">[</span><span class="n">feature_columns</span><span class="p">],</span>
    <span class="n">label_encoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df_cleaned</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]),</span>  <span class="c1"># Pastikan target dalam bentuk numerik</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="c1"># Pipeline dengan KNN dan StandardScaler</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
    <span class="p">(</span><span class="s2">&quot;knn&quot;</span><span class="p">,</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">11</span><span class="p">))</span>
<span class="p">])</span>

<span class="c1"># Pelatihan model KNN</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Evaluasi model</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Akurasi: </span><span class="si">{</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>

<span class="c1"># Visualisasi Decision Boundary</span>
<span class="n">_</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">weights</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axs</span><span class="p">,</span> <span class="p">(</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span> <span class="s2">&quot;distance&quot;</span><span class="p">)):</span>
    <span class="n">clf</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="n">knn__weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">disp</span> <span class="o">=</span> <span class="n">DecisionBoundaryDisplay</span><span class="o">.</span><span class="n">from_estimator</span><span class="p">(</span>
        <span class="n">clf</span><span class="p">,</span>
        <span class="n">X_test</span><span class="p">,</span>
        <span class="n">response_method</span><span class="o">=</span><span class="s2">&quot;predict&quot;</span><span class="p">,</span>
        <span class="n">plot_method</span><span class="o">=</span><span class="s2">&quot;pcolormesh&quot;</span><span class="p">,</span>
        <span class="n">xlabel</span><span class="o">=</span><span class="n">feature_columns</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">ylabel</span><span class="o">=</span><span class="n">feature_columns</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">shading</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">scatter</span> <span class="o">=</span> <span class="n">disp</span><span class="o">.</span><span class="n">ax_</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
        <span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="n">c</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;viridis&quot;</span>
    <span class="p">)</span>
    <span class="n">disp</span><span class="o">.</span><span class="n">ax_</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span>
        <span class="n">scatter</span><span class="o">.</span><span class="n">legend_elements</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span>
        <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower left&quot;</span><span class="p">,</span>
        <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Classes&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">disp</span><span class="o">.</span><span class="n">ax_</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;3-Class classification</span><span class="se">\n</span><span class="s2">(k=</span><span class="si">{</span><span class="n">clf</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">n_neighbors</span><span class="si">}</span><span class="s2">, weights=</span><span class="si">{</span><span class="n">weights</span><span class="si">!r}</span><span class="s2">)&quot;</span>
    <span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Akurasi: 0.8518518518518519
                 precision    recall  f1-score   support

    Iris-setosa       1.00      1.00      1.00        12
Iris-versicolor       0.80      0.57      0.67         7
 Iris-virginica       0.70      0.88      0.78         8

       accuracy                           0.85        27
      macro avg       0.83      0.82      0.81        27
   weighted avg       0.86      0.85      0.85        27
</pre></div>
</div>
<img alt="_images/588514ef628a417a0964ee22a12d199183a200c1dbb9b51adbc9bab79bdc41e7.png" src="_images/588514ef628a417a0964ee22a12d199183a200c1dbb9b51adbc9bab79bdc41e7.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Pilih dua fitur untuk scatter plot</span>
<span class="n">x_feature</span> <span class="o">=</span> <span class="s2">&quot;petal_length&quot;</span>
<span class="n">y_feature</span> <span class="o">=</span> <span class="s2">&quot;petal_width&quot;</span>

<span class="c1"># Warna berdasarkan kelas</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;Iris-setosa&quot;</span><span class="p">:</span> <span class="s2">&quot;blue&quot;</span><span class="p">,</span> <span class="s2">&quot;Iris-versicolor&quot;</span><span class="p">:</span> <span class="s2">&quot;green&quot;</span><span class="p">,</span> <span class="s2">&quot;Iris-virginica&quot;</span><span class="p">:</span> <span class="s2">&quot;red&quot;</span><span class="p">}</span>
<span class="n">df_cleaned</span><span class="p">[</span><span class="s2">&quot;color&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_cleaned</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">colors</span><span class="p">)</span>

<span class="c1"># Plot scatter dengan ukuran (s) dan warna (c)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df_cleaned</span><span class="p">[</span><span class="n">x_feature</span><span class="p">],</span> <span class="n">df_cleaned</span><span class="p">[</span><span class="n">y_feature</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">df_cleaned</span><span class="p">[</span><span class="s2">&quot;color&quot;</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">x_feature</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">y_feature</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Scatter Plot dengan Warna Berdasarkan Class&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/e880d1a88626440344cfca7b38effc6adf68668401f08f8f03a8aefd2401532e.png" src="_images/e880d1a88626440344cfca7b38effc6adf68668401f08f8f03a8aefd2401532e.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Pilih dua fitur untuk scatter plot</span>
<span class="n">x_feature</span> <span class="o">=</span> <span class="s2">&quot;sepal_length&quot;</span>
<span class="n">y_feature</span> <span class="o">=</span> <span class="s2">&quot;sepal_width&quot;</span>

<span class="c1"># Warna berdasarkan kelas</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;Iris-setosa&quot;</span><span class="p">:</span> <span class="s2">&quot;blue&quot;</span><span class="p">,</span> <span class="s2">&quot;Iris-versicolor&quot;</span><span class="p">:</span> <span class="s2">&quot;green&quot;</span><span class="p">,</span> <span class="s2">&quot;Iris-virginica&quot;</span><span class="p">:</span> <span class="s2">&quot;red&quot;</span><span class="p">}</span>
<span class="n">df_cleaned</span><span class="p">[</span><span class="s2">&quot;color&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_cleaned</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">colors</span><span class="p">)</span>

<span class="c1"># Plot scatter dengan ukuran (s) dan warna (c)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df_cleaned</span><span class="p">[</span><span class="n">x_feature</span><span class="p">],</span> <span class="n">df_cleaned</span><span class="p">[</span><span class="n">y_feature</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">df_cleaned</span><span class="p">[</span><span class="s2">&quot;color&quot;</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">x_feature</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">y_feature</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Scatter Plot dengan Warna Berdasarkan Class&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/bda1e50479e37734f740c7dd328347e9010b2a6dc647518a19b1ab0898463bcb.png" src="_images/bda1e50479e37734f740c7dd328347e9010b2a6dc647518a19b1ab0898463bcb.png" />
</div>
</div>
</section>
</section>
<section id="implementasi-naive-bayes-pada-data-iris">
<h1><strong>Implementasi Naive Bayes pada Data IRIS</strong><a class="headerlink" href="#implementasi-naive-bayes-pada-data-iris" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Asumsikan df_merged sudah ada dari kode sebelumnya</span>

<span class="c1"># Encode label kelas ke numerik</span>
<span class="n">label_encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;class_encoded&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">])</span>

<span class="c1"># Data dengan outlier</span>
<span class="n">X_all</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="n">feature_columns</span><span class="p">]</span>
<span class="n">y_all</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;class_encoded&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>  <span class="c1"># Pastikan dalam bentuk array numpy</span>

<span class="c1"># Data tanpa outlier</span>
<span class="n">df_cleaned</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;outlier&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;outlier&quot;</span><span class="p">])</span>
<span class="n">X_clean</span> <span class="o">=</span> <span class="n">df_cleaned</span><span class="p">[</span><span class="n">feature_columns</span><span class="p">]</span>
<span class="n">y_clean</span> <span class="o">=</span> <span class="n">df_cleaned</span><span class="p">[</span><span class="s2">&quot;class_encoded&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>  <span class="c1"># Pastikan dalam bentuk array numpy</span>

<span class="c1"># Split data dengan outlier</span>
<span class="n">X_train_all</span><span class="p">,</span> <span class="n">X_test_all</span><span class="p">,</span> <span class="n">y_train_all</span><span class="p">,</span> <span class="n">y_test_all</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X_all</span><span class="p">,</span> <span class="n">y_all</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Split data tanpa outlier</span>
<span class="n">X_train_clean</span><span class="p">,</span> <span class="n">X_test_clean</span><span class="p">,</span> <span class="n">y_train_clean</span><span class="p">,</span> <span class="n">y_test_clean</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X_clean</span><span class="p">,</span> <span class="n">y_clean</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Inisialisasi model Naive Bayes</span>
<span class="n">gnb</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>

<span class="c1"># Latih dan uji model dengan outlier</span>
<span class="n">y_pred_all</span> <span class="o">=</span> <span class="n">gnb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_all</span><span class="p">,</span> <span class="n">y_train_all</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_all</span><span class="p">)</span>
<span class="n">mislabeled_all</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_test_all</span> <span class="o">!=</span> <span class="n">y_pred_all</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">accuracy_all</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_all</span><span class="p">,</span> <span class="n">y_pred_all</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of mislabeled points with outliers out of a total </span><span class="si">%d</span><span class="s2"> points : </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">X_test_all</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">mislabeled_all</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy with outliers: </span><span class="si">%.2f%%</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">accuracy_all</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>

<span class="c1"># Menampilkan label yang salah pada data dengan outlier</span>
<span class="n">mislabeled_indices_all</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_test_all</span> <span class="o">!=</span> <span class="n">y_pred_all</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mislabeled points with outliers:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">mislabeled_indices_all</span><span class="p">:</span>
    <span class="n">true_label</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">([</span><span class="nb">int</span><span class="p">(</span><span class="n">y_test_all</span><span class="p">[</span><span class="n">i</span><span class="p">])])[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">predicted_label</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">([</span><span class="nb">int</span><span class="p">(</span><span class="n">y_pred_all</span><span class="p">[</span><span class="n">i</span><span class="p">])])[</span><span class="mi">0</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Index: </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">, True Label: </span><span class="si">{</span><span class="n">true_label</span><span class="si">}</span><span class="s2">, Predicted: </span><span class="si">{</span><span class="n">predicted_label</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="c1"># Latih dan uji model tanpa outlier</span>
<span class="n">y_pred_clean</span> <span class="o">=</span> <span class="n">gnb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_clean</span><span class="p">,</span> <span class="n">y_train_clean</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_clean</span><span class="p">)</span>
<span class="n">mislabeled_clean</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_test_clean</span> <span class="o">!=</span> <span class="n">y_pred_clean</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">accuracy_clean</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_clean</span><span class="p">,</span> <span class="n">y_pred_clean</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of mislabeled points without outliers out of a total </span><span class="si">%d</span><span class="s2"> points : </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">X_test_clean</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">mislabeled_clean</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy without outliers: </span><span class="si">%.2f%%</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">accuracy_clean</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>

<span class="c1"># Menampilkan label yang salah pada data tanpa outlier</span>
<span class="n">mislabeled_indices_clean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_test_clean</span> <span class="o">!=</span> <span class="n">y_pred_clean</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mislabeled points without outliers:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">mislabeled_indices_clean</span><span class="p">:</span>
    <span class="n">true_label</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">([</span><span class="nb">int</span><span class="p">(</span><span class="n">y_test_clean</span><span class="p">[</span><span class="n">i</span><span class="p">])])[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">predicted_label</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">([</span><span class="nb">int</span><span class="p">(</span><span class="n">y_pred_clean</span><span class="p">[</span><span class="n">i</span><span class="p">])])[</span><span class="mi">0</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Index: </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">, True Label: </span><span class="si">{</span><span class="n">true_label</span><span class="si">}</span><span class="s2">, Predicted: </span><span class="si">{</span><span class="n">predicted_label</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Visualisasi Confusion Matrix</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test_all</span><span class="p">,</span> <span class="n">y_pred_all</span><span class="p">),</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Blues&quot;</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix with Outliers&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted Label&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;True Label&quot;</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test_clean</span><span class="p">,</span> <span class="n">y_pred_clean</span><span class="p">),</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Blues&quot;</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix without Outliers&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted Label&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;True Label&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of mislabeled points with outliers out of a total 30 points : 24
Accuracy with outliers: 20.00%
Mislabeled points with outliers:
Index: 0, True Label: Iris-versicolor, Predicted: Iris-virginica
Index: 1, True Label: Iris-setosa, Predicted: Iris-versicolor
Index: 2, True Label: Iris-virginica, Predicted: Iris-versicolor
Index: 4, True Label: Iris-versicolor, Predicted: Iris-virginica
Index: 5, True Label: Iris-setosa, Predicted: Iris-versicolor
Index: 7, True Label: Iris-virginica, Predicted: Iris-versicolor
Index: 10, True Label: Iris-virginica, Predicted: Iris-versicolor
Index: 11, True Label: Iris-setosa, Predicted: Iris-versicolor
Index: 12, True Label: Iris-setosa, Predicted: Iris-versicolor
Index: 13, True Label: Iris-setosa, Predicted: Iris-versicolor
Index: 14, True Label: Iris-setosa, Predicted: Iris-versicolor
Index: 15, True Label: Iris-versicolor, Predicted: Iris-virginica
Index: 16, True Label: Iris-virginica, Predicted: Iris-versicolor
Index: 19, True Label: Iris-virginica, Predicted: Iris-versicolor
Index: 20, True Label: Iris-setosa, Predicted: Iris-versicolor
Index: 21, True Label: Iris-virginica, Predicted: Iris-versicolor
Index: 22, True Label: Iris-setosa, Predicted: Iris-versicolor
Index: 23, True Label: Iris-virginica, Predicted: Iris-versicolor
Index: 24, True Label: Iris-virginica, Predicted: Iris-versicolor
Index: 25, True Label: Iris-virginica, Predicted: Iris-versicolor
Index: 26, True Label: Iris-virginica, Predicted: Iris-versicolor
Index: 27, True Label: Iris-virginica, Predicted: Iris-versicolor
Index: 28, True Label: Iris-setosa, Predicted: Iris-versicolor
Index: 29, True Label: Iris-setosa, Predicted: Iris-versicolor

Number of mislabeled points without outliers out of a total 27 points : 3
Accuracy without outliers: 88.89%
Mislabeled points without outliers:
Index: 1, True Label: Iris-versicolor, Predicted: Iris-virginica
Index: 14, True Label: Iris-virginica, Predicted: Iris-versicolor
Index: 26, True Label: Iris-versicolor, Predicted: Iris-virginica
</pre></div>
</div>
<img alt="_images/47db46f8c3bffb12b543b88fb81a97a2abe923a4a4351db12918683a828c7b28.png" src="_images/47db46f8c3bffb12b543b88fb81a97a2abe923a4a4351db12918683a828c7b28.png" />
</div>
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="tugas2.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Tugas 2</p>
      </div>
    </a>
    <a class="right-next"
       href="LOF.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><strong>Deteksi Outlier dengan metode Local Outlier Factor (LOF) dalam Data Understanding</strong></p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#"><strong>Deteksi Outlier dengan K-Nearest Neighbors (KNN) dalam Data Understanding</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kesimpulan"><strong>kesimpulan</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pemisah-outlier-dari-data">Pemisah Outlier dari data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#menghitung-akurasi-data">Menghitung akurasi data</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#implementasi-naive-bayes-pada-data-iris"><strong>Implementasi Naive Bayes pada Data IRIS</strong></a></li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Dina Puspita Sari
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>